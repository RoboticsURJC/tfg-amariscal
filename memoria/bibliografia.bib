@article{neocognitron,
  author  = {Fukushima, Kunihiko},
  title   = {Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
  journal = {NHK Broadcasting Science Research Laboratories},
  month   = {October},
  year    = {1979},
  http    = {https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf}
}

@misc{canonical32bits,
  author       = {J.Pomeyrol},
  howpublished = {Muy Linux},
  title        = {Canonical concreta el soporte de 32-bit para Ubuntu 20.04 LTS},
  journal      = {muylinux.com},
  year         = {2019},
  month        = {September},
  http         = {https://www.muylinux.com/2019/09/19/soporte-32-bit-ubuntu-20-04-lts/}
}

@article{saej3016,
  author  = {SAE, International},
  title   = {SAE J3016 Levels of Driving Automation},
  journal = {SAE J3016},
  year    = {2018},
  month   = {July},
  http    = {https://www.sae.org/standards/content/j3016_201806/}
}

@article{phobos,
  title   = {Phobos: A tool for creating complex robot models},
  author  = {von Szadkowski, Kai and Reichel, Simon},
  journal = {Journal of Open Source Software},
  volume  = {5},
  number  = {45},
  pages   = {1326},
  year    = {2020}
}

@article{adam,
  doi = {10.48550/ARXIV.1412.6980},
  url = {https://arxiv.org/abs/1412.6980},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Adam: A Method for Stochastic Optimization},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{yolov4,
  doi = {10.48550/ARXIV.2004.10934},
  url = {https://arxiv.org/abs/2004.10934},
  author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {YOLOv4: Optimal Speed and Accuracy of Object Detection},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{yolov3,
  title={YOLOv3: An Incremental Improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal = {arXiv},
  year={2018}
}

@article{autopilottesla,
  author  = {Today, Corporates},
  title   = {Why Tesla using Pytorch for Autopilot},
  journal = {Corporates Today},
  year    = {2021},
  month   = {March},
  http    = {https://corporates.today/why-tesla-using-pytorch-for-autopilot}
}

@article{nightvision,
  author  = {Raiciu, Tudor},
  title   = {How Night Vision Works},
  journal = {autoevolution.com},
  year    = {2009},
  month   = {May},
  http    = {https://www.autoevolution.com/news/how-night-vision-works-6891.html}
}

@misc{distanceopencv,
  author  = {Dal, Asadullah},
  title   = {Distance(webcam) Estimation with single-camera OpenCV-python},
  journal = {medium.com},
  year    = {2021},
  month   = {December},
  http    = {https://medium.com/mlearning-ai/distance-estimation-with-single-camera-opencv-python-298a96383c2b}
}

@misc{teslazenrdna2,
  author  = {Ros, Isidro},
  title   = {Tesla monta CPUs Zen de AMD y GPUs RDNA 2 en sus coches},
  journal = {muycomputer.com},
  year    = {2021},
  month   = {November},
  http    = {https://www.muycomputer.com/2021/11/10/tesla-zen-rdna-2-coches/}
}


@article{versus,
	author = {Ayoub, Naeem and Schneider-Kamp, Peter},
	year = {2021},
	month = {05},
	pages = {1091},
	title = {Real-Time On-Board Deep Learning Fault Detection for Autonomous UAV Inspections},
	volume = {10},
	journal = {Electronics},
	doi = {10.3390/electronics10091091}
}

@article{graphcoco,
author = {Padilla, Rafael and Passos, Wesley L. and Dias, Thadeu L. B. and Netto, Sergio L. and da Silva, Eduardo A. B.},
title = {A Comparative Analysis of Object Detection Metrics with a Companion Open-Source Toolkit},
jotnal = {Electronics},
volume = {10},
year = {2021},
number = {3},
article-number = {279},
url = {https://www.mdpi.com/2079-9292/10/3/279},
issn = {2079-9292},
abstract = {Recent outstanding results of supervised object detection in competitions and challenges are often associated with specific metrics and datasets. The evaluation of such methods applied in different contexts have increased the demand for annotated datasets. Annotation tools represent the location and size of objects in distinct formats, leading to a lack of consensus on the representation. Such a scenario often complicates the comparison of object detection methods. This work alleviates this problem along the following lines: (i) It provides an overview of the most relevant evaluation methods used in object detection competitions, highlighting their peculiarities, differences, and advantages; (ii) it examines the most used annotation formats, showing how different implementations may influence the assessment results; and (iii) it provides a novel open-source toolkit supporting different annotation formats and 15 performance metrics, making it easy for researchers to evaluate the performance of their detection algorithms in most known datasets. In addition, this work proposes a new metric, also included in the toolkit, for evaluating object detection in videos that is based on the spatio-temporal overlap between the ground-truth and detected bounding boxes.},
doi = {10.3390/electronics10030279}
}
