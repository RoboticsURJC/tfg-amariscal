\documentclass{beamer}
% pdfpc --notes=right slides.pdf
% "tecla p": para pausar el cronometro
\mode<presentation> {
	\usetheme{CambridgeUS}
	\usecolortheme{crane}
}

\setbeamercolor{titlelike}{parent=structure,bg=yellow!85!orange}

\setbeamertemplate{navigation symbols}{} % ocultar iconos de navegación
\setbeamerfont{subsection in toc}{size=\small} % reducir tamaño en TOC
\setbeamerfont{date}{size=\tiny}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{pgfpages}
\usepackage{listings}
\usepackage{multimedia}
\usepackage[export]{adjustbox}
\usepackage{outlines}

\usepackage{array,tabularx}
\newenvironment{conditions*}
{\par\vspace{\abovedisplayskip}\noindent
\tabularx{\columnwidth}{>{$}l<{$} @{\ : } >{\raggedright\arraybackslash}X}}
{\endtabularx\par\vspace{\belowdisplayskip}}

% USO DE NOTAS
\setbeameroption{hide notes} % Para mostrar u ocultar (hide/show)
% \setbeameroption{show only notes} % Mostrar solo las notas
\setbeameroption{show notes on second screen=right} % Mostrar notas en otra pantalla
\setbeamertemplate{note page}{ % asi solo muestro el texto de las notas
	\insertnote%
}

\hypersetup{
	pdftitle={Defensa de trabajo de fin de grado de Álvaro Mariscal Ávila},
	pdfauthor={Álvaro Mariscal Ávila},
	pdfsubject={Conducción autónoma sobre plataforma real y simulada con seguimiento de carril e identificación de señales de tráfico y peatones mediante redes neuronales},
	pdfkeywords={robotics, vision, neural networks},
	pdfproducer={pdfLaTeX},
	colorlinks=true,
	linkcolor=blue
}
% =========

\title[Conducción autónoma con redes neuronales]{Conducción autónoma sobre plataforma real y simulada con seguimiento de carril e identificación de señales de tráfico y peatones
	mediante redes neuronales}
\author[Álvaro Mariscal Ávila]{Álvaro Mariscal Ávila}
\institute[URJC]
{
	\textit{\href{mailto:a.mariscal.2018@alumnos.urjc.es}{\color{blue}{\underline{a.mariscal.2018@alumnos.urjc.es}}}}\\
	\vspace{0.5cm}
	\includegraphics[width=3cm]{figs/logo-urjc}\\
	\vspace{1cm}
	Trabajo fin de grado
}
\date{5 de julio de 2022}
% =========

% ========= COMIENZO DEL DOCUMENTO
\begin{document}

% ========= Portada inicial con notas
\begin{frame}[plain]
	\large{\titlepage}
	\note[item]{Mi nombre es ...}
	\note[item]{Voy a presentar mi trabajo titulado: Conducción autónoma sobre plataforma real y simulada con seguimiento de carril e identificación de señales de tráfico y
		peatones mediante redes
		neuronales.}
\end{frame}

% ========= Licencia
\begin{frame}
	\input{licencia.tex}
\end{frame}

% ========= Índice o tabla de contenidos (TOC)
\begin{frame}
	\frametitle{Contenidos}
	% \begin{multicols}{2} % si tengo muchas secciones, lo parte en dos columnas
	\tableofcontents[hideallsubsections]
	% \end{multicols}
	\note[item]{La presentación esta dividida en cinco partes.}
\end{frame}

\section*{}
\begin{frame}{}
	\centering \Huge
	\emph{Introducción}
	\note[item]{Para empezar tenemos la introducción para hablar acerca del contexto general.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Capítulo 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section{Introducción}
\subsection{Contexto general}
\begin{frame}
	\frametitle{Inteligencia artificial}
	\begin{itemize}
		\item \textcolor{red}{Entender} y \textcolor{red}{emular} el comportamiento humano.
		\item Dotar a sistemas de cierta \textcolor{red}{inteligencia} y de la capacidad de \textcolor{red}{aprender}.
		\item Visión artificial, aprendizaje automático o aprendizaje profundo.
	\end{itemize}
	\note[item]{Inteligencia artificial: es la disciplina que trata de entender y emular el comportamiento humano.}
	\note[item]{Permite dotar a sistemas, entre los que se encuentran los robots, de cierta inteligencia y de la capacidad de aprender.}
	\note[item]{Multitud de ramas que parten de la IA como visión artificial, aprendizaje automático o aprendizaje profundo.}
\end{frame}

\begin{frame}
	\frametitle{Visión artificial}
	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figs/yolo}
	\end{figure}
	\note[item]{Visión artificial utiliza sensores como las cámaras permiten obtener una información muy completa del entorno.}
	\note[item]{Tiene multitud de aplicaciones entre las que se encuentra la detección de objetos tal y como se observa en la imagen.}
	\note[item]{Para ello es necesario técnicas como Deep Learning o aprendizaje profundo.}
\end{frame}

\begin{frame}
	\frametitle{\textit{Deep Learning}}
	\begin{figure}
		\centering
		\includegraphics[width=6cm]{figs/neuralnetwork}
	\end{figure}
	\begin{outline}
		\1 \textcolor{red}{Neocognitrón} (1979): Red neuronal con 5 o 6 capas para \textcolor{red}{reconocer caracteres japoneses}.
	\end{outline}
	\note[item]{Deep Learning se basa en el uso de redes neuronales artificiales.}
	\note[item]{Estas están inspiradas en el cerebro humano.}
	\note[item]{En el caso de la abstracción al mundo de la computación, una red está formada por una capa de entrada, una de salida y varias internas u ocultas.}
	\note[item]{Estas redes se entrenan previamente mediante lo conocido como datasets. Que son grandes volúmenes de datos, ya sean imágenes, vídeos, sonidos etc.}
	\note[item]{Neocognitrón se considera el inicio del Deep Learning en 1979, que es una red neuronal con 5 o 6 capas para reconocer caracteres japoneses}.
	\note[item]{Además, decir que no existe límite claro para definir número de capas que debe tener una red neuronal
		para considerarla Deep Learning.}
\end{frame}

\subsection{Contexto específico}
\begin{frame}
	\frametitle{Vehículos autónomos}
	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figs/volvovera}
	\end{figure}
	\note[item]{En cuanto al contexto específico en el que se enmarca el trabajo, encontramos los vehículos aútonomos que permiten circular sin conductor.}
	\note[item]{Si bien es cierto que aún no vemos este tipo de vehículos circulando por las ciudades, mucha de la tecnología necesaria ya está disponible en los vehículos
		actuales}
	\note[item]{Existen diferentes niveles de autonomía. En el caso de la fotografía es un camión autónomo de la marca Volvo con nivel de autonomía 5, es decir, automatización
		completa en cualquier situación. Actualmente se están desarrollando pruebas en el puerto de Gotenburgoooooo}
	\note[item]{Y además, decir que la posibilidad de automatizar transportes de mercancías, sería un gran avance por las grandes distancias que recorren, incluyendo en
		algunos casos transporte internacional durante grandes intervalos de tiempo}
\end{frame}

\begin{frame}
	\frametitle{\textit{Autonomous Mobile Robots}, \textit{AMRs}}
	\begin{figure}
		\centering
		\includegraphics[width=8cm]{figs/kivasystems}
	\end{figure}
	\begin{outline}
		\1 Sucesores de los \textcolor{red}{AGVs}.
	\end{outline}
	\note[item]{Son aquellos capaces de navegar por entornos dinámicos, conviviendo con humanos y sabiendo sobreponerse a situaciones para las que no habían sido programados
		explícitamente.}
	\note[item]{Son los sucesores de los AGVs. Estos requieren una cierta infraestructura
		dependiendo del tipo de guiado, ya sea filo-guiados, a través de pintura o a través de cualquier otra técnica que haga que ese vehículo solo pueda funcionar cuando
		se conoce la infraestructura previa que estará presente en el entorno de trabajo.}
	\note[item]{Kiva Systems: comprada por Amazon en 2012. Permiten automatizar sus almacenes en tareas de logística a nivel interno, maximizando la productividad y el
		almacenamiento, tanto en profundidad como en altura, y obviamente minimizando el coste en personal..}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Capítulo 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section*{}
\begin{frame}{}
	\centering \Huge
	\emph{Objetivos}
	\note[item]{Objetivos.}
\end{frame}

\section{Objetivos}
\subsection{Descripción del problema}
\begin{frame}
	\frametitle{Descripción del problema}
	\begin{outline}
		\1 Desarrollar un \textcolor{red}{coche autónomo} capaz de circular por un \textcolor{red}{circuito} en un entorno dinámico, interactuando con objetos propios de
		una ciudad en dos entornos
		distintos:
		\2 Entorno \textcolor{red}{simulado} con \textcolor{red}{\textit{Gazebo}}.
		\2 Entorno \textcolor{red}{real} usando un robot con \textcolor{red}{\textit{Jetson Nano}}.
		\1 En ambos entornos se han de cumplir dos subobjetivos:
		\2 Seguimiento de \textcolor{red}{carril}
		\2 Detección de \textcolor{red}{objetos}
	\end{outline}
	\note[item]{En cuanto a la descripción del problema.}
	\note[item]{Desarrollar coche autónomo capaz de circular por un circuito en un entorno dinámico, interactuando con objetos propios de una ciudad en dos entornos
		distintos:}
	\note[item]{Entorno simulado con Gazebo.}
	\note[item]{Entorno real usando un robot con Jetson Nano}
	\note[item]{En ambos entornos se han de cumplir dos subobjetivos:}
	\note[item]{Seguimiento de carril}
	\note[item]{Detección de objetos}
\end{frame}

\subsection{Requisitos}
\begin{frame}
	\frametitle{Requisitos}
	\begin{itemize}
		\item El sistema operativo utilizado será \textcolor{red}{\textit{GNU/Linux}}, concretamente la distribución \textcolor{red}{\textit{Ubuntu 18.04 LTS}}.
		\item El entorno simulado requerirá la presencia de una tarjeta gráfica dedicada: \textcolor{red}{\textit{NVIDIA}} y \textcolor{red}{\textit{CUDA}}.
		\item El entorno real requerirá un robot con la placa de desarrollo \textcolor{red}{\textit{NVIDIA Jetson Nano}}, ya que esta es una de las placas con
		      \textcolor{red}{\textit{GPU}} más económicas.
		\item El lenguaje de programación utilizado será \textcolor{red}{\textit{Python}}.
	\end{itemize}
	\note[item]{En cuanto a los requisitos.}
	\note[item]{El sistema operativo utilizado será GNU/Linux, concretamente la distribución Ubuntu 18.04 LTS}.
	\note[item]{El entorno simulado requerirá la presencia de una tarjeta gráfica dedicada: NVIDIA y CUDA}.
	\note[item]{El entorno real requerirá un robot con la placa de desarrollo NVIDIA Jetson Nano, ya que esta es una de las placas con
		GPU más económicas.}
	\note[item]{El lenguaje de programación utilizado será Python}.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Capítulo 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section*{}
\begin{frame}{}
	\centering \Huge
	\emph{Plataforma de desarrollo}
	\note[item]{Plataforma de desarrollo.}
\end{frame}

\section{Plataforma de desarrollo}
\subsection{Hardware}
\begin{frame}
	\frametitle{NVIDIA Jetson Nano}
	\begin{outline}
		\1 Placa de desarrollo de \textcolor{red}{bajo coste} con \textcolor{red}{GPU} dedicada.
		\1 Arquitectura \textcolor{red}{\textit{Aarch64}}, soporte para \textcolor{red}{\textit{GNU/Linux}} y puertos \textcolor{red}{\textit{GPIO}}.
	\end{outline}
	\begin{figure}
		\centering
		\includegraphics[width=6cm]{figs/jetsonnano}
	\end{figure}
	\note[item]{La placa de desarrollo utilizada es NVIDIA Jetson Nano por su bajo coste y por tener una GPU dedicada.}
	\note[item]{Arquitectura Aarch64, soporte para GNU/Linux y puertos GPIO}.
\end{frame}

\begin{frame}
	\frametitle{Componentes}
	\begin{figure}
		\centering
		\includegraphics[width=3cm]{figs/motorTT}
		\includegraphics[width=3cm]{figs/l298n}
		\includegraphics[width=2.5cm]{figs/battery2}
		\includegraphics[width=3cm]{figs/tarantula}
		\includegraphics[width=3cm]{figs/camera}
		\includegraphics[width=1.5cm]{figs/tplink}
		\includegraphics[width=3.5cm]{figs/chasis}
	\end{figure}
	\note[item]{En cuanto a los componentes utilizados para ensamblar el robot real.}
	\note[item]{Motores de bajo coste sin odometría.}
	\note[item]{Controlador de motores. Limitaciones motores a pares.}
	\note[item]{Batería 10500mAh para alimentar Jetson Nano.}
	\note[item]{Batería 7.4V para alimentar motores.}
	\note[item]{Cámara USB como sensor principal.}
	\note[item]{Adaptador Wi-Fi para conexión mediante SSH con el robot.}
	\note[item]{Chasis muy usado en proyectos relacionados con Arduino.}
\end{frame}

\subsection{Software}
\begin{frame}
	\frametitle{Software}
	\begin{figure}
		\centering
		\includegraphics[width=2cm]{figs/pythonlogo}\hspace{0.5cm}
		\includegraphics[width=2cm]{figs/freecadlogo}\hspace{0.3cm}
		\includegraphics[width=2.3cm]{figs/blenderlogo}\hspace{0.5cm}
		\includegraphics[width=1.7cm]{figs/gazebologo}\\
		\vspace{1cm}\includegraphics[width=4.3cm]{figs/roslogo}\hspace{0.5cm}
		\includegraphics[width=4cm]{figs/pyqtlogo}
	\end{figure}
	\note[item]{Software utilizado.}
	\note[item]{Python: Lenguaje de programación interpretado que permite una programación rápida y tiene multitud de librerías compatibles.}
	\note[item]{FreeCAD para diseño de piezas en 2D y 3D.}
	\note[item]{Blender permite ensamblar robots y tiene plugins como Phobos que permiten definir su jerarquía.}
	\note[item]{Gazebo como simulador.}
	\note[item]{ROS como middleware para implementar el software utilizando la abstracción que proporciona.}
	\note[item]{PyQT para desarrollar interfaces de usuario.}
\end{frame}

\begin{frame}
	\frametitle{Software relacionado con visión}
	\begin{figure}
		\centering
		\includegraphics[height=2cm]{figs/opencvlogo}\hspace{0.8cm}
		\includegraphics[height=1.5cm]{figs/yolologo}\hspace{0.6cm}
		\includegraphics[width=3.3cm]{figs/labelimg}\hspace{0.8cm}\\
		\vspace{1cm}\includegraphics[width=2.8cm]{figs/darknetlogo}\hspace{0.8cm}
		\includegraphics[width=2.8cm]{figs/jetracerframe}
	\end{figure}
	\note[item]{Software relacionado con visión.}
	\note[item]{OpenCV: librería de visión artificial con multitud de aplicaciones.}
	\note[item]{YOLO: es un algoritmo de detección de objetos muy popular.}
	\note[item]{LabelIMG: permite etiquetar imágenes componer un dataset y entrenar con él.}
	\note[item]{Darknet: framework que permite entrenar y ejecutar redes neuronales.}
	\note[item]{JetRacer: librería que permite entrenar y ejecutar una red para realizar seguimiento de carril.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Capítulo 4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section*{}
\begin{frame}{}
	\centering \Huge
	\emph{Sistema de conducción autónoma}
	\note[item]{Una vez descritos los objetivos y las plataformas utilizadas veamos el desarrollo en sí del proyecto.}
\end{frame}

\section{Sistema de conducción autónoma}
\subsection{Entorno simulado}
\begin{frame}
	\frametitle{Modelo de la ciudad en \textit{Gazebo}}
	\includegraphics[height=3cm]{figs/smallcity}
	\includegraphics[height=3cm]{figs/trafficlightpedestrian}\vspace{1cm}
	\begin{itemize}
		\item Reproducible en el entorno real
		\item Semáforo y peatón dinámico
	\end{itemize}
	\note[item]{Modelo de la ciudad.}
	\note[item]{Uno de los requisitos es que sea reproducible en el entorno real, por eso partiendo de una ciudad de grandes dimensiones se reduce hasta conseguir lo que
		muestra la imagen.}
	\note[item]{La ciudad dispone de elementos dinámicos como un semáforo y un peatón y elementos estáticos como una señal de stop}
\end{frame}

\begin{frame}
	\frametitle{Modelo del vehículo en \textit{FreeCAD}}
	\begin{figure}
		\centering
		\includegraphics[height=4cm]{figs/sketchFreecad}\hspace{0.1cm}
		\includegraphics[height=4cm]{figs/freecad}
	\end{figure}
	\note[item]{Modelo del coche autónomo diseñado en FreeCAD utilizando la herramienta Sketcher para realizar el diseño con cotas y restricciones de verticalidad y
		horizontalidad.}
	\note[item]{A continuación, se proporciona volumen a las piezas.}
\end{frame}

\begin{frame}
	\frametitle{Modelo y jerarquía del vehículo en \textit{Blender}}
	\begin{figure}
		\centering
		\includegraphics[height=7cm]{figs/phobosDiagram}\hspace{0.1cm}
		\includegraphics[width=6cm]{figs/blenderModel}
	\end{figure}
	\note[item]{Una vez diseñadas las piezas en FreeCAD se exportan en STL para utilizarlas en Blender.}
	\note[item]{Se ensambla el robot y se compone su jerarquía con un link principal que es el cuerpo del robot y cuatro links dependientes de este que son las ruedas.}
	\note[item]{Se utilizan joints de tipo continuous para que las ruedas giren y así dotar de movimiento al robot.}
\end{frame}

\begin{frame}
	\frametitle{Modelo del vehículo en \textit{Gazebo}}
	\begin{figure}
		\centering
		\includegraphics[width=8cm]{figs/modelGazebo}
	\end{figure}
	\begin{outline}
		\1 \textcolor{red}{\textit{Plugins}} para movimiento y cámara conectados con \textcolor{red}{\textit{ROS}}
	\end{outline}
	\note[item]{Teniendo el modelo de la ciudad y el modelo del robot se ejecuta en Gazebo.}
	\note[item]{El robot se puede mover a través de topics de ROS y recibe la imagen que ve el robot a través de un subscriptor.}
\end{frame}

\begin{frame}
	\frametitle{Diagrama de clases}
	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figs/diagram6}
	\end{figure}
	\note[item]{Diagrama de clases.}
\end{frame}

\begin{frame}
	\frametitle{Seguimiento de carril}
	\begin{figure}
		\centering
		\includegraphics[width=6cm]{figs/trainedDifficult}
	\end{figure}
	\begin{outline}
		\1 Red \textcolor{red}{\textit{ResNet-18}} preentrenada: convolucional de \textcolor{red}{18} capas con \textcolor{red}{bloques residuales}.
		\1 \textit{Notebooks} de \textcolor{red}{\textit{Jupyter}}.
		\1 Guardado de cada imagen: \textcolor{red}{\textit{x\_y\_identificador\_unico.jpg}}.
		\1 Dataset de 200 imágenes incluyendo situaciones \textcolor{red}{difíciles}.
	\end{outline}
	\note[item]{En cuanto al seguimiento de carril se utiliza un red ResNet-18 preentrenada que es una red convolucional de 18 capas con bloques residuales.}
	\note[item]{Utiliza notebooks de Jupyter.}
	\note[item]{Para entrenar, se guarda cada imagen haciendo click y se guarda con el siguiente nombre: x\_y\_identificador\_unico.jpg.}
	\note[item]{ Se utiliza un dataset de 200 imágenes incluyendo situaciones difíciles.}
\end{frame}

\begin{frame}
	\frametitle{Entrenamiento red seguimiento de carril}
	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figs/simgraphepoch}
	\end{figure}
	\begin{outline}
		\1 En cada \textcolor{red}{\textit{epoch}} se calcula el error cuadrático medio \textcolor{red}{(\textit{loss})}.
		\1 \textcolor{red}{Propagación hacia atrás} de los errores desde la capa de salida hasta la primera capa.
		\1 Error disminuye hasta \textcolor{red}{0.0068}.
	\end{outline}
	\note[item]{Entrenamiento red seguimiento de carril.}
\end{frame}

\begin{frame}
	\frametitle{Salida red seguimiento de carril}
	\begin{figure}
		\centering
		\includegraphics[width=5cm]{figs/outputNNsim}
	\end{figure}
	\begin{outline}
		\1 \textcolor{red}{224} píxeles.
		\1 Entorno experimental: \textcolor{red}{autómata}.
	\end{outline}
	\note[item]{Entrenamiento red seguimiento de carril.}
\end{frame}

\begin{frame}
	\frametitle{Detección de objetos}
	\begin{figure}
		\centering
		\includegraphics[width=5cm]{figs/darknetSimulator}
	\end{figure}
	\begin{outline}
		\1 \textcolor{red}{\textit{YOLO V3 Tiny}}.
		\1 Objetos muy \textcolor{red}{\textit{genéricos}}: alta probabilidad de detección.
		\1 \textcolor{red}{\textit{Bounding Box}}: clase y probabilidad.
	\end{outline}
	\note[item]{Detección de objetos.}
\end{frame}

\begin{frame}
	\frametitle{Detección de semáforo}
	\begin{figure}
		\centering
		\includegraphics[width=2cm, height=4cm]{figs/cropped}\hspace{2cm}\includegraphics[width=2cm, height=4cm]{figs/hsv}\hspace{2cm}\includegraphics[width=2cm,
			height=4cm]{figs/mask}
	\end{figure}
	\note[item]{Detección de semáforo.}
\end{frame}

\begin{frame}
	\frametitle{Ejecución en el simulador}
	\begin{figure}
		\centering
		\includegraphics[width=3.25cm]{figs/simRed}\\\vspace{0.5cm}
		\includegraphics[width=3.25cm]{figs/simGreen}\hspace{1cm}\includegraphics[width=3.25cm]{figs/simStop}
	\end{figure}
	\note[item]{Ejecución en el simulador.}
\end{frame}

\begin{frame}
	\frametitle{Interfaz de usuario}
	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figs/GUI}
	\end{figure}
	\note[item]{Interfaz de usuario.}
\end{frame}

\subsection{Entorno real}
\begin{frame}
	\frametitle{Entorno real}
	\begin{figure}
		\centering
		\includegraphics[width=6cm]{figs/robot}\vspace{0.5cm}\\
		\includegraphics[width=2cm, height=2.5cm]{figs/realstopsign}\hspace{0.7cm}\includegraphics[width=2cm,
			height=2.5cm]{figs/realtrafficlight}\hspace{0.7cm}\includegraphics[width=2cm, height=2.5cm]{figs/realpedestrian}
	\end{figure}
	\note[item]{Entorno real.}
\end{frame}

\begin{frame}
	\frametitle{Circuito inicial}
	\begin{figure}
		\centering
		\includegraphics[width=6cm]{figs/circuit}
	\end{figure}
	\begin{outline}
		\1 Entrenamiento con luz \textcolor{red}{\textit{artificial}}.
	\end{outline}
	\note[item]{Circuito incial.}
\end{frame}

\begin{frame}
	\frametitle{Circuito con objetos}
	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figs/circuitwithobjects2}
	\end{figure}
	\note[item]{Circuito con objetos.}
\end{frame}

\begin{frame}
	\frametitle{\textit{Dataset} objetos reales}
	\begin{figure}
		\centering
		\includegraphics[height=3cm]{figs/datasetone}\hspace{0.5cm}
		\includegraphics[width=4cm]{figs/datasettwo}\hspace{0.5cm}\\
		\vspace{1cm}\includegraphics[width=4cm]{figs/datasetthree}\hspace{0.5cm}
		\includegraphics[width=4cm]{figs/datasetfour}
	\end{figure}
	\note[item]{Dataset objetos reales.}
\end{frame}

\begin{frame}
	\frametitle{Entrenamiento red de detección de objetos}
	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figs/fan}
	\end{figure}
	\begin{outline}
		\1 Portátil con \textcolor{red}{\textit{NVIDIA MX330}} $\simeq 95^\circ C$.
		\1 2000 iteraciones $\simeq$ 3 horas.
		\1 Únicamente con \textcolor{red}{\textit{dataset}} propio.
	\end{outline}
	\note[item]{Entrenamiento red de detección de objetos.}
\end{frame}

\begin{frame}
	\frametitle{Entrenamiento red de detección de objetos}
	\begin{figure}
		\centering
		\includegraphics[width=7cm]{figs/chart}
	\end{figure}
	\note[item]{Entrenamiento red de detección de objetos.}
\end{frame}

\begin{frame}
	\frametitle{Comparación probabilidad de detección}
	\begin{outline}
		\1 Imagen \textcolor{red}{desconocida} para ambas redes.
	\end{outline}
	\begin{figure}
		\centering
		\includegraphics[width=5.8cm]{figs/predictionsoriginal}\hspace{0.1cm}
		\includegraphics[width=5.8cm]{figs/predictionscustom}
	\end{figure}
	\note[item]{Comparación probabilidad de detección.}
	\note[item]{Marca la diferencia entre detectar o no al peatón cuando el robot está en movimiento.}
\end{frame}

\begin{frame}
	\frametitle{Ejecución en el entorno real}
	\begin{figure}
		\centering
		\includegraphics[width=3.5cm, height=3.5cm]{figs/screenshottrafficlight}\\\vspace{0.5cm}
		\includegraphics[width=3.5cm,
			height=3.5cm]{figs/screenshotstopsign}\hspace{1cm}\includegraphics[width=3.5cm, height=3.5cm]{figs/screenshotpedestrian}
	\end{figure}
	\note[item]{Ejecución en el entorno real.}
\end{frame}

% \begin{conditions*}
% 	R & resistencia del material $[\Omega]$\\
% 	\rho & resistividad $[\Omega-m]$\\
% 	l & longitud $[m]$\\
% 	A & área de sección transversal $[m^2]$
% \end{conditions*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Capítulo 5 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section*{}
\begin{frame}{}
	\centering \Huge
	\emph{Conclusiones}
	\note[item]{Para acabar esta presentación, vamos a repasar lo hecho, unas breves conclusiones y las líneas futuras.}
\end{frame}

\section{Conclusiones}
\begin{frame}
	\frametitle{Conclusiones}
	\begin{outline}
		\1 Para lograr los objetivos se han utilizado dos \textcolor{red}{redes neuronales}:
		\2 Seguimiento de carril: librería \textcolor{red}{\textit{JetRacer}} que implementa una red \textcolor{red}{\textit{residual}} \textit{ResNet-18} combinada con un
		\textcolor{red}{controlador}.
		\2 Detección de objetos: \textit{framework} \textcolor{red}{\textit{Darknet}} que permite ejecutar una red \textcolor{red}{\textit{convolucional}} \textit{YOLO V3
			Tiny} previamente entrenada mediante un \textcolor{red}{\textit{dataset}} propio con los objetos reales para aumentar la fiabilidad.
		\1 Todo ello ha sido combinado en dos paquetes \textcolor{red}{\textit{ROS}}, diferenciando entorno simulado y real.
		\1 Limitaciones: \textcolor{red}{ángulo} de la cámara y \textcolor{red}{resolución} de imagen en las redes neuronales.
	\end{outline}
	\note[item]{Conclusiones.}
\end{frame}

\subsection{Líneas futuras}
\begin{frame}
	\frametitle{Líneas futuras}
	\begin{figure}
		\centering
		\includegraphics[width=5cm]{figs/tunel}\hspace{0.5cm}
		\includegraphics[width=5cm]{figs/forest}
	\end{figure}
	\note[item]{Líneas futuras: mayor dataset, túnes, bosques, todo entorno donde exista algo similar a un camino a seguir. También sería interesante obtener los límites en
		izquierda y derecha del carril y no solo el punto central.}
\end{frame}

\begin{frame}[plain]
	\large{\titlepage}
	\note[item]{Vídeo.}
	\note[item]{Eso sería todo. Muchas gracias por su atención.}
\end{frame}

\end{document}